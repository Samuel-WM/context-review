## Historical Perspectives

### 2.1 Statistical Origins



### 2.2 Emergence in Machine Learning


As interest in machine learning began growing, these statistical foundations were the basis to iterative advances that were realized as researchers recognized problems involving related tasks and domains. Multitask learning (MTL) trains tasks in parallel using a shared representation across parameters, increasing generalization [@doi:10.1023/A:1007379606734]. MTL demonstrates how inference can be conditioned on which task is being solved. The shared representation provides a flexible foundation, but requires adaptation based on the current task context, leading to data interacting differently with the same MTL system. For example, in histopathology, a shared encoder can support multiple segmentation tasks alongside classification, with decoder heads adapting to each context [@doi:10.48550/arXiv.2203.00077]. While MTL exploited simultaneous relatedness, researchers also explored the reuse of knowledge, leading to transfer learning. Transfer Learning, in turn,  focused on the ability for knowledge from one domain to be reused to improve the performance of another, often moving from a more general domain to a specific one [@doi:10.1109/TKDE.2009.191]. Context was then reinterpreted as a task label or domain identifier, and adaptivity was achieved by sharing representations or re‑weighting source data to match the target. The trade‑off shifted to balancing shared structure against task‑specific idiosyncrasies. Contextual multi‑armed bandits further integrated context into sequential decision‑making: algorithms like LinUCB modeled expected reward as a linear function of context features and explored actions with high uncertainty [@doi:10.48550/arXiv.2505.16918]. This adaptivity is limited by linearity, foreshadowing the need for deeper models.




### 2.3 Meta-Learning and Representation Learning

### 2.4 Foundation Models and Implicit Adaptivity

MTL
[@doi:10.1023/A:1007379606734]


Covariate Shift
[@doi:10.1007/978-1-4612-1284-3_13]


Bandits
[@doi:10.48550/arXiv.0710.1672]


Transfer Learning
[@doi:10.1109/TKDE.2009.191]


Combo
[@doi:10.48550/arXiv.2502.20153]
